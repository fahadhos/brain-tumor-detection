{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78bf6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "pip install tensorflow\n",
    "pip install keras\n",
    "pip install keras-utils\n",
    "pip install callbacks\n",
    "pip install keras-models\n",
    "\n",
    "pip install keras-octave-conv\n",
    "pip install python-fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ba1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22551a3",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import zipfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fdba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "with zipfile.ZipFile(\"brain tumour ds.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7da9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os # usefull for files or to get the directories\n",
    "import math  # any math related computation\n",
    "import shutil # can move my file from one folder to other\n",
    "import glob #so i don't have to write entire path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5eaf24",
   "metadata": {},
   "source": [
    "## count the number of images is the repective  classes 0  means Brain tumour and 1 means healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51354ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"Brain Tumor Data Set\"\n",
    "number_of_images = {} # creating dictionary key would name of folder and number of images of brain tumour\n",
    "\n",
    "for dir in os.listdir(ROOT_DIR):\n",
    "    number_of_images[dir] = len(os.listdir(os.path.join(ROOT_DIR,dir)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9276f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('Brain Tumor', 17), ('Healthy', 16)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_images.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734adc16",
   "metadata": {},
   "source": [
    "## now split the data such that \n",
    " -  70% for training\n",
    " - 15% for validation\n",
    " - 15% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f422c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataFolder(path, split):\n",
    "    #now creating training folder\n",
    "\n",
    "\n",
    "    if not os.path.exists(\"./\"+path):\n",
    "        os.mkdir(\"./\"+ path)\n",
    "\n",
    "\n",
    "        for dir in os.listdir(ROOT_DIR):\n",
    "            os.makedirs(\"./\"+path+\"/\"+dir)\n",
    "\n",
    "            for img in np.random.choice( a = os.listdir(os.path.join(ROOT_DIR,dir)),\n",
    "                                        size=(math.floor(split*number_of_images[dir])-5)\n",
    "                                        ,replace=False):\n",
    "                O = os.path.join(ROOT_DIR, dir , img)  # path \n",
    "                D = os.path.join(\"./\"+path ,dir)  # destination path\n",
    "                shutil.copy(O,D)\n",
    "                os.remove(O)  # then remove the image which is present on O variable path\n",
    "\n",
    "    else:\n",
    "         print(f\"{path} folder is already exists\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4780c50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train folder is already exists\n"
     ]
    }
   ],
   "source": [
    "dataFolder(\"train\",0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afd2c3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val folder is already exists\n"
     ]
    }
   ],
   "source": [
    "dataFolder(\"val\",0.15) # validation folder 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bb01cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test folder is already exists\n"
     ]
    }
   ],
   "source": [
    "dataFolder(\"test\",0.15) # validation folder 15%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fddee8",
   "metadata": {},
   "source": [
    "## Model creating below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa15f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten , Dense ,BatchNormalization, GlobalAvgPool2D,Activation\n",
    "from keras.models import Sequential\n",
    "from   keras.preprocessing.image import ImageDataGenerator\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f4e3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN MODEL\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), activation = 'relu', input_shape=(224,224,3) ))\n",
    "\n",
    "model.add(Conv2D(filters=36,kernel_size = (3,3), activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size = (3,3), activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size = (3,3), activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss= keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "950abf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 16)      448       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 220, 220, 36)      5220      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 110, 110, 36)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 108, 108, 64)      20800     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 26, 26, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                5537856   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,638,245\n",
      "Trainable params: 5,638,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c21943",
   "metadata": {},
   "source": [
    "## Preparing our image data using data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63a90f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingImages1(path):\n",
    "    \"\"\" \n",
    "    input is path\n",
    "    output is pre processed images\n",
    "    \"\"\"\n",
    "    image_data = ImageDataGenerator(zoom_range= 0.2, shear_range= 0.2, rescale = 1./255, horizontal_flip = True) #data augmentation\n",
    "   \n",
    "    image = image_data.flow_from_directory(directory = path, target_size= (244,244), batch_size=32, class_mode = 'binary')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c7efa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3209 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path = \"train\"\n",
    "train_data = preprocessingImages1(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46997726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Brain Tumor': 0, 'Healthy': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fba6170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingImages2(path):\n",
    "    \"\"\" input is path\n",
    "    output is pre processed images\n",
    "    \"\"\"\n",
    "    image_data = ImageDataGenerator( rescale = 1./255 )\n",
    "    image = image_data.flow_from_directory(directory= path, target_size= (244,244,3), batch_size=32, class_mode = 'binary')\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af6067e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 679 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path = 'test'\n",
    "test_data = preprocessingImages2(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8e5127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 679 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path = 'val'\n",
    "val_data = preprocessingImages2(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "710c1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping and model check point\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Early Stopping\n",
    "es = EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5 , verbose=1 , mode= 'auto')\n",
    "\n",
    "# Model Checkpoint\n",
    "mc = ModelCheckpoint(monitor=\"val_accuracy\", filepath=\"./bestmodel.h5\", verbose=1, save_best_only= True, mode= 'auto')\n",
    "\n",
    "cd = [es, mc]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c18eb3b",
   "metadata": {},
   "source": [
    "Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7de7d58a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# verbose jei execution hocche ta display koray\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m hs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit_generator(\u001b[43mgenerator\u001b[49m,\n\u001b[0;32m      4\u001b[0m                           steps_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m      5\u001b[0m                          epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m      6\u001b[0m                          verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,     \n\u001b[0;32m      7\u001b[0m                          validation_data\u001b[38;5;241m=\u001b[39m val_data,\n\u001b[0;32m      8\u001b[0m                           validation_steps\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m, \n\u001b[0;32m      9\u001b[0m                           callbacks \u001b[38;5;241m=\u001b[39m cd\n\u001b[0;32m     10\u001b[0m                       )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "# verbose jei execution hocche ta display koray\n",
    "\n",
    "hs = model.fit_generator(generator=test_data,\n",
    "                          steps_per_epoch = 8,\n",
    "                         epochs = 30,\n",
    "                         verbose = 1,     \n",
    "                         validation_data= val_data,\n",
    "                          validation_steps= 16, \n",
    "                          callbacks = cd\n",
    "                      )\n",
    "\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18569aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9ca901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3d254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea0d8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae821eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1d4103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2de8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5900c08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
